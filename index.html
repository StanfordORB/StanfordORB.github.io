<!DOCTYPE html>
<html>
<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Stanford-ORB: Real-World 3D Object Inverse Rendering Benchmark</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->
    
    <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous"> -->
    <link rel="stylesheet" href="./resources/bootstrap.min.css">
    <link rel="stylesheet" href="./resources/font-awesome.min.css">
    <link rel="stylesheet" href="./resources/codemirror.min.css">
    <link rel="stylesheet" href="./resources/app.css">
    <link rel="stylesheet" href="./resources/bootstrap.min(1).css">
    <link rel="stylesheet" href="./resources/benchmark_table.css">

    <script src="./resources/jquery.min.js"></script>
    <script src="./resources/bootstrap.min.js"></script>
    <script src="./resources/codemirror.min.js"></script>
    <script src="./resources/clipboard.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script async="" src="https://unpkg.com/es-module-shims@1.8.0/dist/es-module-shims.js"></script>
    <script type="importmap">
        {
          "imports": {
            "three": "https://unpkg.com/three@0.156.1/build/three.module.js",
            "three/controls/OrbitControls": "https://unpkg.com/three@0.156.1/examples/jsm/controls/OrbitControls.js",
            "three/libs/stats": "https://unpkg.com/three@0.156.1/examples/jsm/libs/stats.module.js"
          }
        }
      </script>
    <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
    <style>
        model-viewer {
          width: 300px;
          height: 300px;
        }
      </style>
    <script src="./resources/app.js"></script>
</head>


<body>

<div class="container" id="main">    
    
    <div class="col-md-8 col-md-offset-2" style="margin-bottom: -10px">
        <img src="./resources/logo.png" class="img-responsive" style="scale: 80%" alt="Logo">
    </div>
    <div class="row">
        <h1 class="col-md-12 text-center" style="margin-bottom:2px">
            A Real-World 3D Object Inverse Rendering Benchmark<br>
        </h1>
    </div>
    <h4 class="col-md-12 text-center">
    NeurIPS 2023 Datasets & Benchmarks Track
    </h4>
    <div class="row">
        <div class="col-md-12 text-center">
            <ul class="list-inline" style="margin-bottom:2px">
                <li>
                    <a href="https://zhengfeikuang.com">
                        Zhengfei Kuang*
                    </a>
                </li>
                <li>
                    <a href="https://cs.stanford.edu/~yzzhang/">
                        Yunzhi Zhang*
                    </a>
                </li>
                <li>
                    <a href="https://kovenyu.com/">
                        Hong-Xing "Koven" Yu
                    </a>
                </li>
                <li>
                    <a href="https://samiragarwala.github.io/">
                        Samir Agarwala
                    </a>
                </li>
                <li>
                    <a href="https://elliottwu.com/">
                        Shangzhe Wu
                    </a>
                </li>
                <li>
                    <a href="https://jiajunwu.com/">
                        Jiajun Wu
                    </a>
                </li>
            </ul>
            <p class="text-center">
            Stanford University
            </p>
        </div>
    </div>

    <div class="row">
        <div class="col-md-4 col-md-offset-4 text-center">
            <ul class="nav nav-pills nav-justified">
                <li>
                    <a href="https://arxiv.org/abs/2310.16044">
                        <img src="resources/paper_thumbnail.png" height="60px">
                        <h4><strong>Paper</strong></h4>
                    </a>
                </li>
                <!-- <li>
                    <a href="https://youtu.be/qOfV35y_ppc">
                        <img src="resources/youtube_icon.png" height="60px">
                        <h4><strong>Video</strong></h4>
                    </a>
                </li> -->
                <li>
                    <a href="#_download">
                        <img src="resources/dataset_icon.png" height="60px"/>
                        <h4><strong>Dataset</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/StanfordORB/Stanford-ORB">
                        <img src="resources/github.png" height="60px"/>
                        <h4><strong>Code</strong></h4>
                    </a>
                </li>
            </ul>
        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">

            <h3>
                <b id="#TLDR">TL;DR</b>
            </h3>
            <p class="text-justify">
                We present a novel real-world 3D Object inverse Rendering Benchmark, <b>Stanford-ORB</b>, to evaluate object inverse rendering methods. 
                The benchmark consists of:
                <ul>
                    <li><b>2,795</b> HDR images of <b>14</b> objects captured in <b>7</b> in-the-wild scenes (each object is captured in <b>3</b> scenes);</li>
                    <li><b>418</b> HDR ground truth environment maps aligned with image captures;</li>
                    <li>Studio captured textured mesh of all objects;</li>
                    <li>A set of comphehensive benchmarks for inverse rendering evaluation;</li>
                </ul>
        
            </p>
            <p class="text-justify">
                <b>The benchmark is set to be plug & play</b> -- all data has been cleaned and organized in the most common structures (i.e. Blender, LLFF, Colmap).
                We also provide the scripts for dataloading and evaluation, along with the results from various state-of-the-art methods.
                To test your model, check our <a href="https://github.com/StanfordORB/Stanford-ORB">github page</a> for more details.
            </p>
        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Gallary">Gallary</b>
            </h3>
            <h4>Scanned Meshes (Texture generated from NVDiffRec)</h4>
        </div>        

        <div class="row">
            <div class="col-md-10 col-md-offset-1 mb-4" style="text-align: center">
                <div class="col-md-4">
                    <model-viewer src="./model/grogu.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1" orientation="0deg 0deg 90deg" >
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Grogu</i></p>
                    <model-viewer src="./model/curry.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Curry</i></p>
                </div>
            
                <div class="col-md-4">
                    <model-viewer src="./model/gnome.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Gnome</i></p>
                    <model-viewer src="./model/teapot.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Teapot</i></p>
                </div>
            
                <div class="col-md-4">
                    <model-viewer src="./model/car.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Car</i></p>
                    <model-viewer src="./model/pepsi.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">
                        <div class="progress-bar hide" slot="progress-bar">
                            <div class="update-bar"></div>
                        </div>
                        <button slot="ar-button" id="ar-button">
                            View in your space
                        </button>
                    </model-viewer>
                    <p><i>Pepsi</i></p>
                </div>    
            </div>      
        </div>

        <div class="col-md-8 col-md-offset-2">          
            <h4>Image Captures</h4>
            <img src="./resources/image_gallary.jpg" class="img-responsive" alt="Image Gallary"><br>
        </div>  

    </div>

    
    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Overview">Overview</b>
            </h3>
            <img src="./resources/overview.jpg" class="img-responsive" alt="Overview"><br>
            <p class="text-justify">
                The figure shows the overall pipeline of data capture. For each object,
                <i>Left</i>: we obtain its 3D shape using
                a 3D scanner and Physics-Based Rendering (PBR) materials using high-quality light box images.
                <i>Middle</i>: we also capture multi-view masked images in 3 different in-the-wild scenes, together with
                the ground-truth environment maps. <i>Right</i>: we carefully register the camera poses for all images
                using the scanned mesh and recovered materials, and prepare the data for the evaluation benchmarks.
                Credit to Maurice Svay for the low-poly camera mesh model.
            </p>
        </div>
    </div>

    
    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Benchmark">Benchmark Design</b>
            </h3>

            <p class="text-justify">
                Our benchmark is based on the single-scene reconstrution. 
                That means, to test a model, it should be trained with one of our datapoints (i.e. images of one object captured in one scene) and being evaluted at a time.
                . The evaluation includes:
                <ul>
                    <li><i>Novel View Synthesis</i>: Evaluating the inferred novel views in the same scene;</li>
                    <li><i>Novel Scene Relighting</i>: Evaluating the inferred novel views in novel scenes, given ground-truth environment map;</li>
                    <li><i>Geometry Estimation</i>: Evaluating the reconstructed 3D geometry.</li>
                </ul>
                
                <!-- Furthermore, considering that many inverse rendering methods are compute-intensive, we hereby provide two configurations of the benchmark:
                <ul>
                    <li><i>Stanford-ORB-Full</i>, where the model is required to be trained on all datapoints (14x3 in total);</li>
                    <li><i>Stanford-ORB-Light</i>, where the model only needs to be trained on selected datapoints (7x1 in total);</li>
                </ul> -->
                For more details of our benchmark, please refer to our <a href="https://github.com/StanfordORB/Stanford-ORB">github page</a>.
            <br>         

        </div>        
    </div>
    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Benchmark">Results</b>
            </h3>
            <h4>Quantitative Results</h4>
        </div>
        <div class="col-md-10 col-md-offset-1">
            <br>
            <div class="table-responsive">
            <table class="table">
                <thead>
                <tr>
                    <th class="table_head align-middle" scope="col">Method</th>
                    <th class="table_head align-middle" colspan="3" scope="col">Geometry Estimation</th>
                    <th class="table_head align-middle" colspan="4" scope="col">Novel Scene Relighting</th>
                    <th class="table_head align-middle" colspan="4" scope="col">Novel View Synthesis</th>
                </tr>                
                <tr>
                    <td class="table_elem align-middle"></td>
        
                    <td class="table_elem align-middle">Depth<span>&#8595;</span></td>
                    <td class="table_elem align-middle">Geometry<span>&#8595;</span></td>
                    <td class="table_elem align-middle">Shape<span>&#8595;</span></td>
        
                    <td class="table_elem align-middle">PSNR-H<span>&#8593;</span></td>
                    <td class="table_elem align-middle">PSNR-L<span>&#8593;</span></td>
                    <td class="table_elem align-middle">SSIM<span>&#8593;</span></td>
                    <td class="table_elem align-middle">LPIPS<span>&#8595;</span></td>
        
                    <td class="table_elem align-middle">PSNR-H<span>&#8593;</span></td>
                    <td class="table_elem align-middle">PSNR-L<span>&#8593;</span></td>
                    <td class="table_elem align-middle">SSIM<span>&#8593;</span></td>
                    <td class="table_elem align-middle">LPIPS<span>&#8595;</span></td>
                </tr>
                </thead>
                <tbody>                
                <tr>
                    <th class="table_elem align-middle" colspan="12" scope="col" style="padding: 5px">Novel View Synthesis / 3D Reconstruction Methods</th>
                </tr>  
                <tr>
                    <td class="table_elem">IDR</td>
                    <td class="table_elem">0.35</td>
                    <td class="table_elem">0.05</td>
                    <td class="table_elem table_emph">0.30</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                    <td class="table_elem table_emph">30.11</td>
                    <td class="table_elem table_emph">39.66</td>
                    <td class="table_elem table_emph">0.990</td>
                    <td class="table_elem table_emph">0.017</td>
                </tr>
                <tr>
                    <td class="table_elem">NeRF</td>
                    <td class="table_elem">2.19</td>
                    <td class="table_elem">0.62</td>
                    <td class="table_elem">62.05</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                    <td class="table_elem">26.31</td>
                    <td class="table_elem">33.59</td>
                    <td class="table_elem">0.968</td>
                    <td class="table_elem">0.044</td>
                </tr>                
                <tr>
                    <th class="table_elem align-middle" colspan="12" scope="col" style="padding: 5px">Material Decomposition Methods</th>
                </tr> 
                <tr>
                    <td class="table_elem">Neural-PIL</td>
                    <td class="table_elem">0.86</td>
                    <td class="table_elem">0.29</td>
                    <td class="table_elem">4.14</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                    <td class="table_elem">25.79</td>
                    <td class="table_elem">33.35</td>
                    <td class="table_elem">0.963</td>
                    <td class="table_elem">0.051</td>
                </tr>                
                <tr>
                    <td class="table_elem">PhySG</td>
                    <td class="table_elem">1.90</td>
                    <td class="table_elem">0.17</td>
                    <td class="table_elem">9.28</td>

                    <td class="table_elem">21.81</td>
                    <td class="table_elem">28.11</td>
                    <td class="table_elem">0.960</td>
                    <td class="table_elem">0.055</td>

                    <td class="table_elem">24.24</td>
                    <td class="table_elem">32.15</td>
                    <td class="table_elem">0.974</td>
                    <td class="table_elem">0.047</td>
                </tr>
                <tr>
                    <td class="table_elem">NVDiffRec</td>
                    <td class="table_elem table_emph">0.31</td>
                    <td class="table_elem">0.06</td>
                    <td class="table_elem">0.62</td>

                    <td class="table_elem">22.91</td>
                    <td class="table_elem">29.72</td>
                    <td class="table_elem">0.963</td>
                    <td class="table_elem">0.039</td>

                    <td class="table_elem">21.94</td>
                    <td class="table_elem">28.44</td>
                    <td class="table_elem">0.969</td>
                    <td class="table_elem">0.030</td>
                </tr>
                <tr>
                    <td class="table_elem">NeRD</td>
                    <td class="table_elem">1.39</td>
                    <td class="table_elem">0.28</td>
                    <td class="table_elem">13.70</td>

                    <td class="table_elem">23.29</td>
                    <td class="table_elem">29.65</td>
                    <td class="table_elem">0.957</td>
                    <td class="table_elem">0.059</td>

                    <td class="table_elem">25.83</td>
                    <td class="table_elem">32.61</td>
                    <td class="table_elem">0.963</td>
                    <td class="table_elem">0.054</td>
                </tr>
                <tr>
                    <td class="table_elem">NeRFactor</td>
                    <td class="table_elem">0.87</td>
                    <td class="table_elem">0.29</td>
                    <td class="table_elem">9.53</td>

                    <td class="table_elem">23.54</td>
                    <td class="table_elem">30.38</td>
                    <td class="table_elem">0.969</td>
                    <td class="table_elem">0.048</td>

                    <td class="table_elem">26.06</td>
                    <td class="table_elem">33.47</td>
                    <td class="table_elem">0.973</td>
                    <td class="table_elem">0.046</td>
                </tr>                
                <tr>
                    <td class="table_elem">InvRender</td>
                    <td class="table_elem">0.59</td>
                    <td class="table_elem">0.06</td>
                    <td class="table_elem">0.44</td>

                    <td class="table_elem">23.76</td>
                    <td class="table_elem">30.83</td>
                    <td class="table_elem">0.970</td>
                    <td class="table_elem">0.046</td>

                    <td class="table_elem">25.91</td>
                    <td class="table_elem">34.01</td>
                    <td class="table_elem">0.977</td>
                    <td class="table_elem">0.042</td>
                </tr>                 
                <tr>
                    <td class="table_elem">NVDiffRecMC</td>
                    <td class="table_elem">0.32</td>
                    <td class="table_elem table_emph">0.04</td>
                    <td class="table_elem">0.51</td>

                    <td class="table_elem table_emph">24.43</td>
                    <td class="table_elem table_emph">31.60</td>
                    <td class="table_elem table_emph">0.972</td>
                    <td class="table_elem table_emph">0.036</td>

                    <td class="table_elem">28.03</td>
                    <td class="table_elem">36.40</td>
                    <td class="table_elem">0.982</td>
                    <td class="table_elem">0.028</td>
                </tr>                 
                <tr>
                    <th class="table_elem align-middle" colspan="12" scope="col" style="padding: 5px">Single-View Prediction Methods</th>
                </tr>         
                <tr>
                    <td class="table_elem">SI-SVBRDF</td>
                    <td class="table_elem">81.48</td>
                    <td class="table_elem">0.29</td>
                    <td class="table_elem">N/A</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                </tr>                
                <tr>
                    <td class="table_elem">SIRFS</td>
                    <td class="table_elem">N/A</td>
                    <td class="table_elem">0.59</td>
                    <td class="table_elem">N/A</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                </tr>                 
                <tr>
                    <th class="table_elem align-middle" colspan="12" scope="col" style="padding: 5px">Reference Results</th>
                </tr>                  
                <tr>
                    <td class="table_elem">NVDiffRecMC+GT Mesh</td>
                    <td class="table_elem align-middle" colspan="3">N/A</td>
                    <td class="table_elem">25.08</td>
                    <td class="table_elem">32.28</td>
                    <td class="table_elem">0.974</td>
                    <td class="table_elem">0.027</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                </tr>                  
                <tr>
                    <td class="table_elem">NVDiffRec+GT Mesh</td>
                    <td class="table_elem align-middle" colspan="3">N/A</td>
                    <td class="table_elem">24.93</td>
                    <td class="table_elem">32.42</td>
                    <td class="table_elem">0.975</td>
                    <td class="table_elem">0.027</td>
                    <td class="table_elem align-middle" colspan="4">N/A</td>
                </tr>   
                </tbody>
            </table>
            </div>
        </div>           

        <div class="col-xs-8 col-md-offset-2" style="height:40px;">
            <h4>Qualitative Results</h4>
        </div>
        <div class="col-md-10 col-md-offset-1">
            <img src="./resources/qualitative.png" class="img-responsive" alt="Novel View Synthesis"><br>
        </div>    
    </div>

    <div class="row" id="_download">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Download">Download Links</b>
            </h3>

            <p class="text-justify">
                For convenience proposes, we provide separate download links for images organized in different data structures, and the auxiliary files. 
            </p>
            <ul>
                <li>
                    <a href="https://downloads.cs.stanford.edu/viscam/StanfordORB/blender_LDR.tar.gz">blender_LDR.tar.gz</a> (11G): 
                    LDR images and camera files (organized as the Blender Dataset structure);
                </li>
                <li>
                    <a href="https://downloads.cs.stanford.edu/viscam/StanfordORB/blender_HDR.tar.gz">blender_HDR.tar.gz</a> (72G): 
                    HDR images and camera files (organized as the Blender Dataset structure);

                </li>
                <li>
                    <a href="https://downloads.cs.stanford.edu/viscam/StanfordORB/llff_colmap_LDR.tar.gz">llff_colmap_LDR.tar.gz</a> (11G): 
                    LDR images and camera files (organized as the LLFF Dataset structure and as the Colmap's structure);
                </li>
                <li>
                    <a href="https://downloads.cs.stanford.edu/viscam/StanfordORB/llff_colmap_HDR.tar.gz">llff_colmap_HDR.tar.gz</a> (72G): 
                    HDR images and camera files (organized as the LLFF Dataset structure and as the Colmap's structure); 
                </li>               
                <li>
                    <a href="https://downloads.cs.stanford.edu/viscam/StanfordORB/ground_truth.tar.gz">ground_truth.tar.gz</a> (4.8G): 
                    GT environment maps, 3D meshes, depth maps, normal maps, and pesudo-gt albedo maps. 
                </li>         
            </ul>
            If your model prefers the Blender Dataset, download blender_LDR.tar.gz, blender_HDR.tar.gz and ground_truth.tar.gz. 
            Otherwise download llff_colmap_LDR.tar.gz, llff_colmap_HDR.tar.gz and ground_truth.tar.gz. Notice that the HDR dataset is also required 
            for HDR evaluations even if your model runs in LDR.
        </div>           
        
    </div>    
    
    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b id="#Citation">Citation</b>
            </h3>
        </div>
    </div> 

    <div class="row">
        <div class="col-md-8 col-md-offset-2" >
        <p style="color:gray; text-align:right" >
            The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a>.
        </p>
        </div>
    </div>
</div>
</body>
</html>